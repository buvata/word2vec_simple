{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re \n",
    "import nltk.corpus\n",
    "import nltk.stem\n",
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw ='He is the king . The king is royal . She is the royal queen ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw=corpus_raw.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for word in corpus_raw.split():\n",
    "    if word !='.' :\n",
    "        words.append(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'is', 'the', 'king', 'the', 'king', 'is', 'royal', 'she', 'is', 'the', 'royal', 'queen']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=set(words)\n",
    "word2int={}\n",
    "int2word={}\n",
    "vocab_size=len(words)  # total number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'he', 'is', 'king', 'queen', 'royal', 'she', 'the'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,word in enumerate(words):\n",
    "    word2int[word]=i\n",
    "    int2word[i]=word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "king\n"
     ]
    }
   ],
   "source": [
    "print(word2int['king'])\n",
    "print(int2word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw sentences \n",
    "raw_sentences=corpus_raw.split('.')\n",
    "sentences=[]\n",
    "for sentence in raw_sentences:\n",
    "    sentences.append(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for sentence in sentences:\n",
    "    for word_index, word in enumerate(sentence):\n",
    "        for nb_word in sentence[max(word_index-WINDOW_SIZE,0):min(word_index+WINDOW_SIZE,len(sentence))+1]:\n",
    "            if nb_word!=word:\n",
    "                data.append([word,nb_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['he', 'is'],\n",
       " ['he', 'the'],\n",
       " ['is', 'he'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['the', 'he'],\n",
       " ['the', 'is'],\n",
       " ['the', 'king'],\n",
       " ['king', 'is'],\n",
       " ['king', 'the'],\n",
       " ['the', 'king'],\n",
       " ['the', 'is'],\n",
       " ['king', 'the'],\n",
       " ['king', 'is'],\n",
       " ['king', 'royal'],\n",
       " ['is', 'the'],\n",
       " ['is', 'king'],\n",
       " ['is', 'royal'],\n",
       " ['royal', 'king'],\n",
       " ['royal', 'is'],\n",
       " ['she', 'is'],\n",
       " ['she', 'the'],\n",
       " ['is', 'she'],\n",
       " ['is', 'the'],\n",
       " ['is', 'royal'],\n",
       " ['the', 'she'],\n",
       " ['the', 'is'],\n",
       " ['the', 'royal'],\n",
       " ['the', 'queen'],\n",
       " ['royal', 'is'],\n",
       " ['royal', 'the'],\n",
       " ['royal', 'queen'],\n",
       " ['queen', 'the'],\n",
       " ['queen', 'royal']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(data_point_index,vocab_size):\n",
    "    temp=np.zeros(vocab_size)\n",
    "    temp[data_point_index]=1\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "for data_word in data:\n",
    "    X_train.append(to_one_hot(word2int[data_word[0]],vocab_size))\n",
    "    Y_train.append(to_one_hot(word2int[data_word[1]],vocab_size)) \n",
    "\n",
    "X_train=np.asarray(X_train)\n",
    "Y_train=np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making placeholders \n",
    "x=tf.placeholder(tf.float32,shape=(None,vocab_size))\n",
    "y_label=tf.placeholder(tf.float32,shape=(None,vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=5  # matrix embedding \n",
    "\n",
    "W1=tf.Variable(tf.random_normal([vocab_size,EMBEDDING_DIM]))\n",
    "\n",
    "b1=tf.Variable(tf.random_normal([EMBEDDING_DIM]))  # bias\n",
    "\n",
    "hidden_representation=tf.add(tf.matmul(x,W1),b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2=tf.Variable(tf.random_normal([EMBEDDING_DIM,vocab_size]))\n",
    "\n",
    "b2=tf.Variable(tf.random_normal([vocab_size]))\n",
    "\n",
    "prediction=tf.nn.softmax(tf.add(tf.matmul(hidden_representation,W2),b2))\n",
    "#loss function \n",
    "cross_entropy_loss=tf.reduce_mean(-tf.reduce_sum(y_label*tf.log(prediction),reduction_indices=[1]))\n",
    "\n",
    "train_step=tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model \n",
    "sess=tf.Session()\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss: ', 4.6640916)\n",
      "('loss: ', 4.0712118)\n",
      "('loss: ', 3.6306162)\n",
      "('loss: ', 3.3011224)\n",
      "('loss: ', 3.0626962)\n",
      "('loss: ', 2.8934097)\n",
      "('loss: ', 2.7726676)\n",
      "('loss: ', 2.684217)\n",
      "('loss: ', 2.6166742)\n",
      "('loss: ', 2.5627804)\n",
      "('loss: ', 2.5180902)\n",
      "('loss: ', 2.4798584)\n",
      "('loss: ', 2.4463329)\n",
      "('loss: ', 2.4163475)\n",
      "('loss: ', 2.3890967)\n",
      "('loss: ', 2.3640049)\n",
      "('loss: ', 2.340651)\n",
      "('loss: ', 2.3187203)\n",
      "('loss: ', 2.2979741)\n",
      "('loss: ', 2.2782269)\n",
      "('loss: ', 2.2593355)\n",
      "('loss: ', 2.2411864)\n",
      "('loss: ', 2.2236888)\n",
      "('loss: ', 2.2067709)\n",
      "('loss: ', 2.1903727)\n",
      "('loss: ', 2.1744463)\n",
      "('loss: ', 2.1589515)\n",
      "('loss: ', 2.1438549)\n",
      "('loss: ', 2.1291289)\n",
      "('loss: ', 2.1147494)\n",
      "('loss: ', 2.1006973)\n",
      "('loss: ', 2.0869546)\n",
      "('loss: ', 2.0735066)\n",
      "('loss: ', 2.0603406)\n",
      "('loss: ', 2.0474453)\n",
      "('loss: ', 2.034811)\n",
      "('loss: ', 2.022429)\n",
      "('loss: ', 2.0102923)\n",
      "('loss: ', 1.9983935)\n",
      "('loss: ', 1.9867274)\n",
      "('loss: ', 1.9752884)\n",
      "('loss: ', 1.9640727)\n",
      "('loss: ', 1.9530759)\n",
      "('loss: ', 1.9422944)\n",
      "('loss: ', 1.9317259)\n",
      "('loss: ', 1.9213676)\n",
      "('loss: ', 1.9112172)\n",
      "('loss: ', 1.9012731)\n",
      "('loss: ', 1.891534)\n",
      "('loss: ', 1.8819985)\n",
      "('loss: ', 1.8726656)\n",
      "('loss: ', 1.8635342)\n",
      "('loss: ', 1.8546042)\n",
      "('loss: ', 1.8458748)\n",
      "('loss: ', 1.837345)\n",
      "('loss: ', 1.829015)\n",
      "('loss: ', 1.8208838)\n",
      "('loss: ', 1.8129503)\n",
      "('loss: ', 1.8052138)\n",
      "('loss: ', 1.7976732)\n",
      "('loss: ', 1.7903267)\n",
      "('loss: ', 1.7831733)\n",
      "('loss: ', 1.7762098)\n",
      "('loss: ', 1.7694346)\n",
      "('loss: ', 1.7628438)\n",
      "('loss: ', 1.7564349)\n",
      "('loss: ', 1.7502037)\n",
      "('loss: ', 1.744146)\n",
      "('loss: ', 1.7382573)\n",
      "('loss: ', 1.7325327)\n",
      "('loss: ', 1.7269672)\n",
      "('loss: ', 1.7215552)\n",
      "('loss: ', 1.7162911)\n",
      "('loss: ', 1.7111692)\n",
      "('loss: ', 1.7061834)\n",
      "('loss: ', 1.7013283)\n",
      "('loss: ', 1.6965977)\n",
      "('loss: ', 1.6919861)\n",
      "('loss: ', 1.6874876)\n",
      "('loss: ', 1.6830974)\n",
      "('loss: ', 1.6788098)\n",
      "('loss: ', 1.6746202)\n",
      "('loss: ', 1.6705236)\n",
      "('loss: ', 1.6665158)\n",
      "('loss: ', 1.6625926)\n",
      "('loss: ', 1.6587503)\n",
      "('loss: ', 1.6549851)\n",
      "('loss: ', 1.6512938)\n",
      "('loss: ', 1.6476734)\n",
      "('loss: ', 1.6441212)\n",
      "('loss: ', 1.6406344)\n",
      "('loss: ', 1.6372107)\n",
      "('loss: ', 1.6338484)\n",
      "('loss: ', 1.630545)\n",
      "('loss: ', 1.6272992)\n",
      "('loss: ', 1.6241089)\n",
      "('loss: ', 1.620973)\n",
      "('loss: ', 1.6178902)\n",
      "('loss: ', 1.6148592)\n",
      "('loss: ', 1.6118785)\n",
      "('loss: ', 1.6089478)\n",
      "('loss: ', 1.6060658)\n",
      "('loss: ', 1.6032313)\n",
      "('loss: ', 1.6004441)\n",
      "('loss: ', 1.597703)\n",
      "('loss: ', 1.5950077)\n",
      "('loss: ', 1.5923567)\n",
      "('loss: ', 1.5897504)\n",
      "('loss: ', 1.5871878)\n",
      "('loss: ', 1.5846682)\n",
      "('loss: ', 1.582191)\n",
      "('loss: ', 1.5797561)\n",
      "('loss: ', 1.5773624)\n",
      "('loss: ', 1.5750098)\n",
      "('loss: ', 1.5726975)\n",
      "('loss: ', 1.5704252)\n",
      "('loss: ', 1.5681922)\n",
      "('loss: ', 1.5659981)\n",
      "('loss: ', 1.5638423)\n",
      "('loss: ', 1.5617247)\n",
      "('loss: ', 1.5596441)\n",
      "('loss: ', 1.5576005)\n",
      "('loss: ', 1.555593)\n",
      "('loss: ', 1.5536214)\n",
      "('loss: ', 1.551685)\n",
      "('loss: ', 1.5497831)\n",
      "('loss: ', 1.5479153)\n",
      "('loss: ', 1.5460811)\n",
      "('loss: ', 1.5442799)\n",
      "('loss: ', 1.542511)\n",
      "('loss: ', 1.5407737)\n",
      "('loss: ', 1.5390675)\n",
      "('loss: ', 1.5373919)\n",
      "('loss: ', 1.5357466)\n",
      "('loss: ', 1.5341303)\n",
      "('loss: ', 1.5325428)\n",
      "('loss: ', 1.5309834)\n",
      "('loss: ', 1.5294514)\n",
      "('loss: ', 1.5279465)\n",
      "('loss: ', 1.5264677)\n",
      "('loss: ', 1.5250146)\n",
      "('loss: ', 1.5235866)\n",
      "('loss: ', 1.5221828)\n",
      "('loss: ', 1.520803)\n",
      "('loss: ', 1.5194466)\n",
      "('loss: ', 1.5181127)\n",
      "('loss: ', 1.5168009)\n",
      "('loss: ', 1.5155104)\n",
      "('loss: ', 1.5142411)\n",
      "('loss: ', 1.5129919)\n",
      "('loss: ', 1.5117627)\n",
      "('loss: ', 1.5105528)\n",
      "('loss: ', 1.5093616)\n",
      "('loss: ', 1.5081887)\n",
      "('loss: ', 1.5070333)\n",
      "('loss: ', 1.5058954)\n",
      "('loss: ', 1.5047742)\n",
      "('loss: ', 1.5036691)\n",
      "('loss: ', 1.5025798)\n",
      "('loss: ', 1.5015063)\n",
      "('loss: ', 1.5004474)\n",
      "('loss: ', 1.499403)\n",
      "('loss: ', 1.4983729)\n",
      "('loss: ', 1.4973565)\n",
      "('loss: ', 1.4963534)\n",
      "('loss: ', 1.4953632)\n",
      "('loss: ', 1.4943857)\n",
      "('loss: ', 1.4934204)\n",
      "('loss: ', 1.4924669)\n",
      "('loss: ', 1.4915252)\n",
      "('loss: ', 1.4905946)\n",
      "('loss: ', 1.4896752)\n",
      "('loss: ', 1.4887662)\n",
      "('loss: ', 1.4878677)\n",
      "('loss: ', 1.4869792)\n",
      "('loss: ', 1.4861007)\n",
      "('loss: ', 1.4852316)\n",
      "('loss: ', 1.484372)\n",
      "('loss: ', 1.4835215)\n",
      "('loss: ', 1.4826796)\n",
      "('loss: ', 1.4818465)\n",
      "('loss: ', 1.4810216)\n",
      "('loss: ', 1.4802051)\n",
      "('loss: ', 1.4793968)\n",
      "('loss: ', 1.4785961)\n",
      "('loss: ', 1.477803)\n",
      "('loss: ', 1.4770174)\n",
      "('loss: ', 1.4762388)\n",
      "('loss: ', 1.4754674)\n",
      "('loss: ', 1.4747032)\n",
      "('loss: ', 1.4739455)\n",
      "('loss: ', 1.4731945)\n",
      "('loss: ', 1.47245)\n",
      "('loss: ', 1.4717118)\n",
      "('loss: ', 1.4709796)\n",
      "('loss: ', 1.4702537)\n",
      "('loss: ', 1.4695336)\n",
      "('loss: ', 1.4688193)\n",
      "('loss: ', 1.4681106)\n",
      "('loss: ', 1.4674076)\n",
      "('loss: ', 1.46671)\n",
      "('loss: ', 1.4660177)\n",
      "('loss: ', 1.4653306)\n",
      "('loss: ', 1.4646485)\n",
      "('loss: ', 1.4639715)\n",
      "('loss: ', 1.4632994)\n",
      "('loss: ', 1.4626322)\n",
      "('loss: ', 1.4619697)\n",
      "('loss: ', 1.4613116)\n",
      "('loss: ', 1.4606582)\n",
      "('loss: ', 1.4600095)\n",
      "('loss: ', 1.4593648)\n",
      "('loss: ', 1.4587245)\n",
      "('loss: ', 1.4580888)\n",
      "('loss: ', 1.4574567)\n",
      "('loss: ', 1.456829)\n",
      "('loss: ', 1.456205)\n",
      "('loss: ', 1.4555851)\n",
      "('loss: ', 1.4549692)\n",
      "('loss: ', 1.454357)\n",
      "('loss: ', 1.4537483)\n",
      "('loss: ', 1.4531436)\n",
      "('loss: ', 1.4525424)\n",
      "('loss: ', 1.4519447)\n",
      "('loss: ', 1.4513506)\n",
      "('loss: ', 1.4507599)\n",
      "('loss: ', 1.4501724)\n",
      "('loss: ', 1.4495884)\n",
      "('loss: ', 1.4490077)\n",
      "('loss: ', 1.4484301)\n",
      "('loss: ', 1.4478557)\n",
      "('loss: ', 1.4472846)\n",
      "('loss: ', 1.4467164)\n",
      "('loss: ', 1.4461514)\n",
      "('loss: ', 1.4455893)\n",
      "('loss: ', 1.44503)\n",
      "('loss: ', 1.4444739)\n",
      "('loss: ', 1.4439204)\n",
      "('loss: ', 1.4433699)\n",
      "('loss: ', 1.4428221)\n",
      "('loss: ', 1.4422771)\n",
      "('loss: ', 1.4417348)\n",
      "('loss: ', 1.4411952)\n",
      "('loss: ', 1.4406581)\n",
      "('loss: ', 1.4401238)\n",
      "('loss: ', 1.439592)\n",
      "('loss: ', 1.4390627)\n",
      "('loss: ', 1.438536)\n",
      "('loss: ', 1.4380118)\n",
      "('loss: ', 1.43749)\n",
      "('loss: ', 1.4369707)\n",
      "('loss: ', 1.4364537)\n",
      "('loss: ', 1.435939)\n",
      "('loss: ', 1.4354267)\n",
      "('loss: ', 1.4349167)\n",
      "('loss: ', 1.4344091)\n",
      "('loss: ', 1.4339037)\n",
      "('loss: ', 1.4334005)\n",
      "('loss: ', 1.4328996)\n",
      "('loss: ', 1.4324008)\n",
      "('loss: ', 1.4319042)\n",
      "('loss: ', 1.43141)\n",
      "('loss: ', 1.4309175)\n",
      "('loss: ', 1.4304272)\n",
      "('loss: ', 1.4299393)\n",
      "('loss: ', 1.4294533)\n",
      "('loss: ', 1.4289693)\n",
      "('loss: ', 1.4284874)\n",
      "('loss: ', 1.4280074)\n",
      "('loss: ', 1.4275293)\n",
      "('loss: ', 1.4270535)\n",
      "('loss: ', 1.4265795)\n",
      "('loss: ', 1.4261074)\n",
      "('loss: ', 1.4256372)\n",
      "('loss: ', 1.4251691)\n",
      "('loss: ', 1.4247029)\n",
      "('loss: ', 1.4242386)\n",
      "('loss: ', 1.4237759)\n",
      "('loss: ', 1.4233154)\n",
      "('loss: ', 1.4228565)\n",
      "('loss: ', 1.4223996)\n",
      "('loss: ', 1.4219445)\n",
      "('loss: ', 1.4214913)\n",
      "('loss: ', 1.4210399)\n",
      "('loss: ', 1.4205903)\n",
      "('loss: ', 1.4201422)\n",
      "('loss: ', 1.4196962)\n",
      "('loss: ', 1.4192518)\n",
      "('loss: ', 1.4188092)\n",
      "('loss: ', 1.4183683)\n",
      "('loss: ', 1.4179295)\n",
      "('loss: ', 1.4174919)\n",
      "('loss: ', 1.4170564)\n",
      "('loss: ', 1.4166225)\n",
      "('loss: ', 1.4161904)\n",
      "('loss: ', 1.4157599)\n",
      "('loss: ', 1.4153311)\n",
      "('loss: ', 1.414904)\n",
      "('loss: ', 1.4144785)\n",
      "('loss: ', 1.4140549)\n",
      "('loss: ', 1.413633)\n",
      "('loss: ', 1.4132128)\n",
      "('loss: ', 1.4127938)\n",
      "('loss: ', 1.4123771)\n",
      "('loss: ', 1.4119616)\n",
      "('loss: ', 1.4115478)\n",
      "('loss: ', 1.4111358)\n",
      "('loss: ', 1.4107255)\n",
      "('loss: ', 1.4103167)\n",
      "('loss: ', 1.4099096)\n",
      "('loss: ', 1.4095039)\n",
      "('loss: ', 1.4091003)\n",
      "('loss: ', 1.4086981)\n",
      "('loss: ', 1.4082974)\n",
      "('loss: ', 1.4078984)\n",
      "('loss: ', 1.4075011)\n",
      "('loss: ', 1.4071054)\n",
      "('loss: ', 1.4067115)\n",
      "('loss: ', 1.4063189)\n",
      "('loss: ', 1.4059281)\n",
      "('loss: ', 1.4055389)\n",
      "('loss: ', 1.4051514)\n",
      "('loss: ', 1.4047652)\n",
      "('loss: ', 1.404381)\n",
      "('loss: ', 1.4039983)\n",
      "('loss: ', 1.403617)\n",
      "('loss: ', 1.4032375)\n",
      "('loss: ', 1.4028597)\n",
      "('loss: ', 1.4024833)\n",
      "('loss: ', 1.4021086)\n",
      "('loss: ', 1.4017354)\n",
      "('loss: ', 1.4013638)\n",
      "('loss: ', 1.4009942)\n",
      "('loss: ', 1.4006258)\n",
      "('loss: ', 1.4002593)\n",
      "('loss: ', 1.3998941)\n",
      "('loss: ', 1.3995306)\n",
      "('loss: ', 1.3991687)\n",
      "('loss: ', 1.3988085)\n",
      "('loss: ', 1.39845)\n",
      "('loss: ', 1.398093)\n",
      "('loss: ', 1.3977376)\n",
      "('loss: ', 1.3973838)\n",
      "('loss: ', 1.3970315)\n",
      "('loss: ', 1.3966812)\n",
      "('loss: ', 1.3963321)\n",
      "('loss: ', 1.3959848)\n",
      "('loss: ', 1.3956391)\n",
      "('loss: ', 1.395295)\n",
      "('loss: ', 1.3949524)\n",
      "('loss: ', 1.3946115)\n",
      "('loss: ', 1.3942723)\n",
      "('loss: ', 1.3939347)\n",
      "('loss: ', 1.3935986)\n",
      "('loss: ', 1.3932639)\n",
      "('loss: ', 1.3929313)\n",
      "('loss: ', 1.3926001)\n",
      "('loss: ', 1.3922706)\n",
      "('loss: ', 1.3919425)\n",
      "('loss: ', 1.3916161)\n",
      "('loss: ', 1.3912914)\n",
      "('loss: ', 1.3909682)\n",
      "('loss: ', 1.3906468)\n",
      "('loss: ', 1.3903267)\n",
      "('loss: ', 1.3900084)\n",
      "('loss: ', 1.3896916)\n",
      "('loss: ', 1.3893765)\n",
      "('loss: ', 1.3890631)\n",
      "('loss: ', 1.3887513)\n",
      "('loss: ', 1.3884408)\n",
      "('loss: ', 1.3881323)\n",
      "('loss: ', 1.3878253)\n",
      "('loss: ', 1.3875197)\n",
      "('loss: ', 1.3872159)\n",
      "('loss: ', 1.3869139)\n",
      "('loss: ', 1.386613)\n",
      "('loss: ', 1.3863142)\n",
      "('loss: ', 1.3860166)\n",
      "('loss: ', 1.3857207)\n",
      "('loss: ', 1.3854265)\n",
      "('loss: ', 1.385134)\n",
      "('loss: ', 1.3848429)\n",
      "('loss: ', 1.3845534)\n",
      "('loss: ', 1.3842653)\n",
      "('loss: ', 1.3839792)\n",
      "('loss: ', 1.3836946)\n",
      "('loss: ', 1.3834115)\n",
      "('loss: ', 1.38313)\n",
      "('loss: ', 1.3828499)\n",
      "('loss: ', 1.3825715)\n",
      "('loss: ', 1.3822947)\n",
      "('loss: ', 1.3820195)\n",
      "('loss: ', 1.3817457)\n",
      "('loss: ', 1.3814738)\n",
      "('loss: ', 1.3812032)\n",
      "('loss: ', 1.3809341)\n",
      "('loss: ', 1.3806667)\n",
      "('loss: ', 1.3804007)\n",
      "('loss: ', 1.3801364)\n",
      "('loss: ', 1.3798736)\n",
      "('loss: ', 1.3796122)\n",
      "('loss: ', 1.3793525)\n",
      "('loss: ', 1.3790942)\n",
      "('loss: ', 1.3788375)\n",
      "('loss: ', 1.3785825)\n",
      "('loss: ', 1.3783287)\n",
      "('loss: ', 1.3780767)\n",
      "('loss: ', 1.377826)\n",
      "('loss: ', 1.3775769)\n",
      "('loss: ', 1.3773293)\n",
      "('loss: ', 1.3770831)\n",
      "('loss: ', 1.3768386)\n",
      "('loss: ', 1.3765954)\n",
      "('loss: ', 1.3763536)\n",
      "('loss: ', 1.3761134)\n",
      "('loss: ', 1.3758746)\n",
      "('loss: ', 1.3756374)\n",
      "('loss: ', 1.3754015)\n",
      "('loss: ', 1.3751673)\n",
      "('loss: ', 1.3749343)\n",
      "('loss: ', 1.3747028)\n",
      "('loss: ', 1.3744727)\n",
      "('loss: ', 1.3742441)\n",
      "('loss: ', 1.3740169)\n",
      "('loss: ', 1.3737911)\n",
      "('loss: ', 1.3735666)\n",
      "('loss: ', 1.3733436)\n",
      "('loss: ', 1.3731221)\n",
      "('loss: ', 1.372902)\n",
      "('loss: ', 1.3726834)\n",
      "('loss: ', 1.3724657)\n",
      "('loss: ', 1.3722497)\n",
      "('loss: ', 1.372035)\n",
      "('loss: ', 1.3718215)\n",
      "('loss: ', 1.3716097)\n",
      "('loss: ', 1.371399)\n",
      "('loss: ', 1.3711897)\n",
      "('loss: ', 1.3709816)\n",
      "('loss: ', 1.3707749)\n",
      "('loss: ', 1.3705696)\n",
      "('loss: ', 1.3703656)\n",
      "('loss: ', 1.3701627)\n",
      "('loss: ', 1.3699614)\n",
      "('loss: ', 1.3697612)\n",
      "('loss: ', 1.3695623)\n",
      "('loss: ', 1.3693647)\n",
      "('loss: ', 1.3691683)\n",
      "('loss: ', 1.3689731)\n",
      "('loss: ', 1.3687793)\n",
      "('loss: ', 1.3685865)\n",
      "('loss: ', 1.3683952)\n",
      "('loss: ', 1.3682051)\n",
      "('loss: ', 1.3680162)\n",
      "('loss: ', 1.3678285)\n",
      "('loss: ', 1.3676419)\n",
      "('loss: ', 1.3674566)\n",
      "('loss: ', 1.3672724)\n",
      "('loss: ', 1.3670894)\n",
      "('loss: ', 1.3669077)\n",
      "('loss: ', 1.366727)\n",
      "('loss: ', 1.3665476)\n",
      "('loss: ', 1.3663691)\n",
      "('loss: ', 1.3661919)\n",
      "('loss: ', 1.3660158)\n",
      "('loss: ', 1.3658408)\n",
      "('loss: ', 1.3656671)\n",
      "('loss: ', 1.3654945)\n",
      "('loss: ', 1.3653228)\n",
      "('loss: ', 1.3651522)\n",
      "('loss: ', 1.3649827)\n",
      "('loss: ', 1.3648144)\n",
      "('loss: ', 1.364647)\n",
      "('loss: ', 1.3644807)\n",
      "('loss: ', 1.3643157)\n",
      "('loss: ', 1.3641514)\n",
      "('loss: ', 1.3639883)\n",
      "('loss: ', 1.3638263)\n",
      "('loss: ', 1.3636652)\n",
      "('loss: ', 1.3635052)\n",
      "('loss: ', 1.3633461)\n",
      "('loss: ', 1.363188)\n",
      "('loss: ', 1.363031)\n",
      "('loss: ', 1.3628749)\n",
      "('loss: ', 1.3627198)\n",
      "('loss: ', 1.3625659)\n",
      "('loss: ', 1.3624126)\n",
      "('loss: ', 1.3622603)\n",
      "('loss: ', 1.3621092)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss: ', 1.3619587)\n",
      "('loss: ', 1.3618095)\n",
      "('loss: ', 1.361661)\n",
      "('loss: ', 1.3615134)\n",
      "('loss: ', 1.3613667)\n",
      "('loss: ', 1.3612208)\n",
      "('loss: ', 1.3610761)\n",
      "('loss: ', 1.3609324)\n",
      "('loss: ', 1.3607892)\n",
      "('loss: ', 1.3606468)\n",
      "('loss: ', 1.3605055)\n",
      "('loss: ', 1.3603649)\n",
      "('loss: ', 1.3602253)\n",
      "('loss: ', 1.3600867)\n",
      "('loss: ', 1.3599485)\n",
      "('loss: ', 1.3598114)\n",
      "('loss: ', 1.359675)\n",
      "('loss: ', 1.3595395)\n",
      "('loss: ', 1.3594049)\n",
      "('loss: ', 1.359271)\n",
      "('loss: ', 1.3591381)\n",
      "('loss: ', 1.3590057)\n",
      "('loss: ', 1.3588742)\n",
      "('loss: ', 1.3587433)\n",
      "('loss: ', 1.3586133)\n",
      "('loss: ', 1.358484)\n",
      "('loss: ', 1.3583556)\n",
      "('loss: ', 1.358228)\n",
      "('loss: ', 1.3581009)\n",
      "('loss: ', 1.3579748)\n",
      "('loss: ', 1.3578492)\n",
      "('loss: ', 1.3577244)\n",
      "('loss: ', 1.3576003)\n",
      "('loss: ', 1.3574769)\n",
      "('loss: ', 1.3573543)\n",
      "('loss: ', 1.3572323)\n",
      "('loss: ', 1.357111)\n",
      "('loss: ', 1.3569903)\n",
      "('loss: ', 1.3568705)\n",
      "('loss: ', 1.3567514)\n",
      "('loss: ', 1.3566328)\n",
      "('loss: ', 1.3565149)\n",
      "('loss: ', 1.3563976)\n",
      "('loss: ', 1.356281)\n",
      "('loss: ', 1.3561651)\n",
      "('loss: ', 1.3560497)\n",
      "('loss: ', 1.3559351)\n",
      "('loss: ', 1.355821)\n",
      "('loss: ', 1.3557075)\n",
      "('loss: ', 1.3555948)\n",
      "('loss: ', 1.3554826)\n",
      "('loss: ', 1.3553709)\n",
      "('loss: ', 1.3552601)\n",
      "('loss: ', 1.3551499)\n",
      "('loss: ', 1.3550401)\n",
      "('loss: ', 1.3549306)\n",
      "('loss: ', 1.354822)\n",
      "('loss: ', 1.354714)\n",
      "('loss: ', 1.3546065)\n",
      "('loss: ', 1.3544997)\n",
      "('loss: ', 1.3543932)\n",
      "('loss: ', 1.3542875)\n",
      "('loss: ', 1.3541822)\n",
      "('loss: ', 1.3540775)\n",
      "('loss: ', 1.3539733)\n",
      "('loss: ', 1.3538697)\n",
      "('loss: ', 1.3537667)\n",
      "('loss: ', 1.3536642)\n",
      "('loss: ', 1.3535622)\n",
      "('loss: ', 1.3534606)\n",
      "('loss: ', 1.3533596)\n",
      "('loss: ', 1.3532591)\n",
      "('loss: ', 1.3531591)\n",
      "('loss: ', 1.3530598)\n",
      "('loss: ', 1.3529607)\n",
      "('loss: ', 1.3528624)\n",
      "('loss: ', 1.3527642)\n",
      "('loss: ', 1.3526667)\n",
      "('loss: ', 1.3525696)\n",
      "('loss: ', 1.3524733)\n",
      "('loss: ', 1.3523771)\n",
      "('loss: ', 1.3522815)\n",
      "('loss: ', 1.3521862)\n",
      "('loss: ', 1.3520917)\n",
      "('loss: ', 1.3519974)\n",
      "('loss: ', 1.3519037)\n",
      "('loss: ', 1.3518102)\n",
      "('loss: ', 1.3517174)\n",
      "('loss: ', 1.3516248)\n",
      "('loss: ', 1.3515331)\n",
      "('loss: ', 1.3514414)\n",
      "('loss: ', 1.3513503)\n",
      "('loss: ', 1.3512596)\n",
      "('loss: ', 1.3511695)\n",
      "('loss: ', 1.3510795)\n",
      "('loss: ', 1.3509901)\n",
      "('loss: ', 1.3509011)\n",
      "('loss: ', 1.3508124)\n",
      "('loss: ', 1.3507242)\n",
      "('loss: ', 1.3506365)\n",
      "('loss: ', 1.350549)\n",
      "('loss: ', 1.350462)\n",
      "('loss: ', 1.3503754)\n",
      "('loss: ', 1.3502892)\n",
      "('loss: ', 1.3502035)\n",
      "('loss: ', 1.3501179)\n",
      "('loss: ', 1.3500329)\n",
      "('loss: ', 1.3499482)\n",
      "('loss: ', 1.3498639)\n",
      "('loss: ', 1.3497801)\n",
      "('loss: ', 1.3496964)\n",
      "('loss: ', 1.3496132)\n",
      "('loss: ', 1.3495305)\n",
      "('loss: ', 1.3494481)\n",
      "('loss: ', 1.3493661)\n",
      "('loss: ', 1.3492842)\n",
      "('loss: ', 1.3492028)\n",
      "('loss: ', 1.3491218)\n",
      "('loss: ', 1.349041)\n",
      "('loss: ', 1.3489606)\n",
      "('loss: ', 1.3488806)\n",
      "('loss: ', 1.348801)\n",
      "('loss: ', 1.3487217)\n",
      "('loss: ', 1.3486427)\n",
      "('loss: ', 1.348564)\n",
      "('loss: ', 1.3484857)\n",
      "('loss: ', 1.3484079)\n",
      "('loss: ', 1.3483301)\n",
      "('loss: ', 1.3482527)\n",
      "('loss: ', 1.3481758)\n",
      "('loss: ', 1.3480991)\n",
      "('loss: ', 1.3480226)\n",
      "('loss: ', 1.3479466)\n",
      "('loss: ', 1.3478708)\n",
      "('loss: ', 1.3477954)\n",
      "('loss: ', 1.3477201)\n",
      "('loss: ', 1.3476454)\n",
      "('loss: ', 1.347571)\n",
      "('loss: ', 1.3474966)\n",
      "('loss: ', 1.3474226)\n",
      "('loss: ', 1.3473493)\n",
      "('loss: ', 1.3472757)\n",
      "('loss: ', 1.3472027)\n",
      "('loss: ', 1.3471299)\n",
      "('loss: ', 1.3470573)\n",
      "('loss: ', 1.3469853)\n",
      "('loss: ', 1.3469133)\n",
      "('loss: ', 1.3468418)\n",
      "('loss: ', 1.3467704)\n",
      "('loss: ', 1.3466995)\n",
      "('loss: ', 1.3466285)\n",
      "('loss: ', 1.3465582)\n",
      "('loss: ', 1.3464879)\n",
      "('loss: ', 1.3464179)\n",
      "('loss: ', 1.3463482)\n",
      "('loss: ', 1.3462789)\n",
      "('loss: ', 1.3462096)\n",
      "('loss: ', 1.3461409)\n",
      "('loss: ', 1.3460722)\n",
      "('loss: ', 1.3460038)\n",
      "('loss: ', 1.3459357)\n",
      "('loss: ', 1.345868)\n",
      "('loss: ', 1.3458002)\n",
      "('loss: ', 1.3457329)\n",
      "('loss: ', 1.3456659)\n",
      "('loss: ', 1.3455992)\n",
      "('loss: ', 1.3455324)\n",
      "('loss: ', 1.3454663)\n",
      "('loss: ', 1.3454001)\n",
      "('loss: ', 1.3453342)\n",
      "('loss: ', 1.3452687)\n",
      "('loss: ', 1.3452033)\n",
      "('loss: ', 1.3451381)\n",
      "('loss: ', 1.3450733)\n",
      "('loss: ', 1.3450086)\n",
      "('loss: ', 1.3449444)\n",
      "('loss: ', 1.3448802)\n",
      "('loss: ', 1.3448163)\n",
      "('loss: ', 1.3447526)\n",
      "('loss: ', 1.3446891)\n",
      "('loss: ', 1.3446258)\n",
      "('loss: ', 1.3445629)\n",
      "('loss: ', 1.3445001)\n",
      "('loss: ', 1.3444376)\n",
      "('loss: ', 1.3443751)\n",
      "('loss: ', 1.3443133)\n",
      "('loss: ', 1.3442512)\n",
      "('loss: ', 1.3441896)\n",
      "('loss: ', 1.3441283)\n",
      "('loss: ', 1.3440669)\n",
      "('loss: ', 1.3440059)\n",
      "('loss: ', 1.3439453)\n",
      "('loss: ', 1.3438846)\n",
      "('loss: ', 1.3438243)\n",
      "('loss: ', 1.3437641)\n",
      "('loss: ', 1.3437041)\n",
      "('loss: ', 1.3436444)\n",
      "('loss: ', 1.343585)\n",
      "('loss: ', 1.3435255)\n",
      "('loss: ', 1.3434665)\n",
      "('loss: ', 1.3434076)\n",
      "('loss: ', 1.3433489)\n",
      "('loss: ', 1.3432903)\n",
      "('loss: ', 1.3432322)\n",
      "('loss: ', 1.3431741)\n",
      "('loss: ', 1.3431162)\n",
      "('loss: ', 1.3430583)\n",
      "('loss: ', 1.343001)\n",
      "('loss: ', 1.3429437)\n",
      "('loss: ', 1.3428866)\n",
      "('loss: ', 1.3428297)\n",
      "('loss: ', 1.342773)\n",
      "('loss: ', 1.3427165)\n",
      "('loss: ', 1.3426601)\n",
      "('loss: ', 1.342604)\n",
      "('loss: ', 1.342548)\n",
      "('loss: ', 1.3424921)\n",
      "('loss: ', 1.3424368)\n",
      "('loss: ', 1.3423814)\n",
      "('loss: ', 1.3423262)\n",
      "('loss: ', 1.3422711)\n",
      "('loss: ', 1.3422163)\n",
      "('loss: ', 1.3421617)\n",
      "('loss: ', 1.3421073)\n",
      "('loss: ', 1.3420529)\n",
      "('loss: ', 1.3419988)\n",
      "('loss: ', 1.3419449)\n",
      "('loss: ', 1.3418913)\n",
      "('loss: ', 1.3418376)\n",
      "('loss: ', 1.3417844)\n",
      "('loss: ', 1.3417311)\n",
      "('loss: ', 1.3416781)\n",
      "('loss: ', 1.3416253)\n",
      "('loss: ', 1.3415726)\n",
      "('loss: ', 1.3415201)\n",
      "('loss: ', 1.3414676)\n",
      "('loss: ', 1.3414155)\n",
      "('loss: ', 1.3413638)\n",
      "('loss: ', 1.3413118)\n",
      "('loss: ', 1.3412601)\n",
      "('loss: ', 1.3412086)\n",
      "('loss: ', 1.3411573)\n",
      "('loss: ', 1.3411063)\n",
      "('loss: ', 1.3410552)\n",
      "('loss: ', 1.3410044)\n",
      "('loss: ', 1.3409538)\n",
      "('loss: ', 1.3409033)\n",
      "('loss: ', 1.3408531)\n",
      "('loss: ', 1.3408029)\n",
      "('loss: ', 1.3407528)\n",
      "('loss: ', 1.340703)\n",
      "('loss: ', 1.3406534)\n",
      "('loss: ', 1.3406039)\n",
      "('loss: ', 1.3405545)\n",
      "('loss: ', 1.3405054)\n",
      "('loss: ', 1.3404562)\n",
      "('loss: ', 1.3404074)\n",
      "('loss: ', 1.3403587)\n",
      "('loss: ', 1.3403101)\n",
      "('loss: ', 1.3402617)\n",
      "('loss: ', 1.3402135)\n",
      "('loss: ', 1.3401653)\n",
      "('loss: ', 1.3401175)\n",
      "('loss: ', 1.3400698)\n",
      "('loss: ', 1.3400221)\n",
      "('loss: ', 1.3399746)\n",
      "('loss: ', 1.3399272)\n",
      "('loss: ', 1.3398801)\n",
      "('loss: ', 1.3398329)\n",
      "('loss: ', 1.3397862)\n",
      "('loss: ', 1.3397394)\n",
      "('loss: ', 1.3396928)\n",
      "('loss: ', 1.3396463)\n",
      "('loss: ', 1.3396001)\n",
      "('loss: ', 1.339554)\n",
      "('loss: ', 1.3395079)\n",
      "('loss: ', 1.3394619)\n",
      "('loss: ', 1.3394163)\n",
      "('loss: ', 1.3393707)\n",
      "('loss: ', 1.3393254)\n",
      "('loss: ', 1.3392801)\n",
      "('loss: ', 1.3392349)\n",
      "('loss: ', 1.33919)\n",
      "('loss: ', 1.3391451)\n",
      "('loss: ', 1.3391004)\n",
      "('loss: ', 1.3390558)\n",
      "('loss: ', 1.3390113)\n",
      "('loss: ', 1.3389671)\n",
      "('loss: ', 1.3389231)\n",
      "('loss: ', 1.3388789)\n",
      "('loss: ', 1.338835)\n",
      "('loss: ', 1.3387913)\n",
      "('loss: ', 1.3387477)\n",
      "('loss: ', 1.3387041)\n",
      "('loss: ', 1.3386608)\n",
      "('loss: ', 1.3386176)\n",
      "('loss: ', 1.3385745)\n",
      "('loss: ', 1.3385315)\n",
      "('loss: ', 1.3384889)\n",
      "('loss: ', 1.3384463)\n",
      "('loss: ', 1.3384037)\n",
      "('loss: ', 1.3383613)\n",
      "('loss: ', 1.3383189)\n",
      "('loss: ', 1.3382769)\n",
      "('loss: ', 1.3382349)\n",
      "('loss: ', 1.3381929)\n",
      "('loss: ', 1.3381512)\n",
      "('loss: ', 1.3381096)\n",
      "('loss: ', 1.3380681)\n",
      "('loss: ', 1.3380268)\n",
      "('loss: ', 1.3379854)\n",
      "('loss: ', 1.3379444)\n",
      "('loss: ', 1.3379035)\n",
      "('loss: ', 1.3378626)\n",
      "('loss: ', 1.3378218)\n",
      "('loss: ', 1.3377812)\n",
      "('loss: ', 1.3377409)\n",
      "('loss: ', 1.3377004)\n",
      "('loss: ', 1.3376602)\n",
      "('loss: ', 1.33762)\n",
      "('loss: ', 1.3375802)\n",
      "('loss: ', 1.3375404)\n",
      "('loss: ', 1.3375006)\n",
      "('loss: ', 1.3374608)\n",
      "('loss: ', 1.3374214)\n",
      "('loss: ', 1.3373821)\n",
      "('loss: ', 1.3373427)\n",
      "('loss: ', 1.3373036)\n",
      "('loss: ', 1.3372647)\n",
      "('loss: ', 1.3372259)\n",
      "('loss: ', 1.3371869)\n",
      "('loss: ', 1.3371483)\n",
      "('loss: ', 1.3371097)\n",
      "('loss: ', 1.3370714)\n",
      "('loss: ', 1.3370332)\n",
      "('loss: ', 1.336995)\n",
      "('loss: ', 1.336957)\n",
      "('loss: ', 1.3369188)\n",
      "('loss: ', 1.336881)\n",
      "('loss: ', 1.3368434)\n",
      "('loss: ', 1.3368058)\n",
      "('loss: ', 1.3367683)\n",
      "('loss: ', 1.3367308)\n",
      "('loss: ', 1.3366936)\n",
      "('loss: ', 1.3366566)\n",
      "('loss: ', 1.3366195)\n",
      "('loss: ', 1.3365828)\n",
      "('loss: ', 1.3365457)\n",
      "('loss: ', 1.336509)\n",
      "('loss: ', 1.3364725)\n",
      "('loss: ', 1.3364362)\n",
      "('loss: ', 1.3363996)\n",
      "('loss: ', 1.3363634)\n",
      "('loss: ', 1.3363274)\n",
      "('loss: ', 1.3362913)\n",
      "('loss: ', 1.3362552)\n",
      "('loss: ', 1.3362195)\n",
      "('loss: ', 1.3361839)\n",
      "('loss: ', 1.3361483)\n",
      "('loss: ', 1.336113)\n",
      "('loss: ', 1.3360775)\n",
      "('loss: ', 1.3360422)\n",
      "('loss: ', 1.3360071)\n",
      "('loss: ', 1.3359721)\n",
      "('loss: ', 1.335937)\n",
      "('loss: ', 1.3359022)\n",
      "('loss: ', 1.3358675)\n",
      "('loss: ', 1.335833)\n",
      "('loss: ', 1.3357984)\n",
      "('loss: ', 1.3357641)\n",
      "('loss: ', 1.3357297)\n",
      "('loss: ', 1.3356955)\n",
      "('loss: ', 1.3356613)\n",
      "('loss: ', 1.3356273)\n",
      "('loss: ', 1.3355933)\n",
      "('loss: ', 1.3355596)\n",
      "('loss: ', 1.335526)\n",
      "('loss: ', 1.3354924)\n",
      "('loss: ', 1.335459)\n",
      "('loss: ', 1.3354254)\n",
      "('loss: ', 1.3353921)\n",
      "('loss: ', 1.3353591)\n",
      "('loss: ', 1.335326)\n",
      "('loss: ', 1.3352929)\n",
      "('loss: ', 1.33526)\n",
      "('loss: ', 1.3352273)\n",
      "('loss: ', 1.3351946)\n",
      "('loss: ', 1.335162)\n",
      "('loss: ', 1.3351296)\n",
      "('loss: ', 1.3350972)\n",
      "('loss: ', 1.3350649)\n",
      "('loss: ', 1.3350326)\n",
      "('loss: ', 1.3350006)\n",
      "('loss: ', 1.3349686)\n",
      "('loss: ', 1.3349367)\n",
      "('loss: ', 1.3349049)\n",
      "('loss: ', 1.3348732)\n",
      "('loss: ', 1.3348416)\n",
      "('loss: ', 1.3348101)\n",
      "('loss: ', 1.3347788)\n",
      "('loss: ', 1.3347473)\n",
      "('loss: ', 1.3347161)\n",
      "('loss: ', 1.3346851)\n",
      "('loss: ', 1.3346539)\n",
      "('loss: ', 1.334623)\n",
      "('loss: ', 1.3345921)\n",
      "('loss: ', 1.3345613)\n",
      "('loss: ', 1.3345307)\n",
      "('loss: ', 1.3345002)\n",
      "('loss: ', 1.3344697)\n",
      "('loss: ', 1.3344393)\n",
      "('loss: ', 1.334409)\n",
      "('loss: ', 1.3343786)\n",
      "('loss: ', 1.3343487)\n",
      "('loss: ', 1.3343185)\n",
      "('loss: ', 1.3342886)\n",
      "('loss: ', 1.3342588)\n",
      "('loss: ', 1.3342291)\n",
      "('loss: ', 1.3341993)\n",
      "('loss: ', 1.33417)\n",
      "('loss: ', 1.3341404)\n",
      "('loss: ', 1.334111)\n",
      "('loss: ', 1.3340816)\n",
      "('loss: ', 1.3340523)\n",
      "('loss: ', 1.3340234)\n",
      "('loss: ', 1.3339943)\n",
      "('loss: ', 1.3339654)\n",
      "('loss: ', 1.3339363)\n",
      "('loss: ', 1.3339076)\n",
      "('loss: ', 1.3338789)\n",
      "('loss: ', 1.3338503)\n",
      "('loss: ', 1.3338218)\n",
      "('loss: ', 1.3337933)\n",
      "('loss: ', 1.333765)\n",
      "('loss: ', 1.3337368)\n",
      "('loss: ', 1.3337085)\n",
      "('loss: ', 1.3336803)\n",
      "('loss: ', 1.3336524)\n",
      "('loss: ', 1.3336245)\n",
      "('loss: ', 1.3335966)\n",
      "('loss: ', 1.3335689)\n",
      "('loss: ', 1.3335412)\n",
      "('loss: ', 1.3335136)\n",
      "('loss: ', 1.3334861)\n",
      "('loss: ', 1.3334587)\n",
      "('loss: ', 1.3334314)\n",
      "('loss: ', 1.3334041)\n",
      "('loss: ', 1.3333769)\n",
      "('loss: ', 1.3333497)\n",
      "('loss: ', 1.3333228)\n",
      "('loss: ', 1.3332957)\n",
      "('loss: ', 1.3332688)\n",
      "('loss: ', 1.3332422)\n",
      "('loss: ', 1.3332154)\n",
      "('loss: ', 1.3331889)\n",
      "('loss: ', 1.3331623)\n",
      "('loss: ', 1.3331358)\n",
      "('loss: ', 1.3331096)\n",
      "('loss: ', 1.3330832)\n",
      "('loss: ', 1.3330569)\n",
      "('loss: ', 1.3330307)\n",
      "('loss: ', 1.3330047)\n",
      "('loss: ', 1.3329786)\n",
      "('loss: ', 1.3329529)\n",
      "('loss: ', 1.3329269)\n",
      "('loss: ', 1.3329012)\n",
      "('loss: ', 1.3328755)\n",
      "('loss: ', 1.3328501)\n",
      "('loss: ', 1.3328245)\n",
      "('loss: ', 1.332799)\n",
      "('loss: ', 1.3327736)\n",
      "('loss: ', 1.3327484)\n",
      "('loss: ', 1.332723)\n",
      "('loss: ', 1.3326979)\n",
      "('loss: ', 1.3326731)\n",
      "('loss: ', 1.3326479)\n",
      "('loss: ', 1.332623)\n",
      "('loss: ', 1.3325981)\n",
      "('loss: ', 1.3325734)\n",
      "('loss: ', 1.3325486)\n",
      "('loss: ', 1.3325239)\n",
      "('loss: ', 1.3324994)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loss: ', 1.3324749)\n",
      "('loss: ', 1.3324504)\n",
      "('loss: ', 1.3324262)\n",
      "('loss: ', 1.332402)\n",
      "('loss: ', 1.3323778)\n",
      "('loss: ', 1.3323536)\n",
      "('loss: ', 1.3323295)\n",
      "('loss: ', 1.3323057)\n",
      "('loss: ', 1.3322818)\n",
      "('loss: ', 1.3322579)\n",
      "('loss: ', 1.3322343)\n",
      "('loss: ', 1.3322105)\n",
      "('loss: ', 1.3321867)\n",
      "('loss: ', 1.3321633)\n",
      "('loss: ', 1.3321398)\n",
      "('loss: ', 1.3321162)\n",
      "('loss: ', 1.332093)\n",
      "('loss: ', 1.3320698)\n",
      "('loss: ', 1.3320465)\n",
      "('loss: ', 1.3320235)\n",
      "('loss: ', 1.3320003)\n",
      "('loss: ', 1.3319772)\n",
      "('loss: ', 1.3319545)\n",
      "('loss: ', 1.3319316)\n",
      "('loss: ', 1.3319088)\n",
      "('loss: ', 1.3318861)\n",
      "('loss: ', 1.3318634)\n",
      "('loss: ', 1.3318408)\n",
      "('loss: ', 1.3318183)\n",
      "('loss: ', 1.3317958)\n"
     ]
    }
   ],
   "source": [
    "n_iters=1000\n",
    "\n",
    "for _ in range(n_iters):\n",
    "    sess.run(train_step,feed_dict={x:X_train,y_label:Y_train})\n",
    "    print('loss: ',sess.run(cross_entropy_loss,feed_dict={x:X_train, y_label:Y_train}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70162368  1.02727377  0.67414278 -0.40907124 -0.04813511]\n",
      " [ 1.31534505 -0.90174574 -2.54694676  0.80336714 -0.21204521]\n",
      " [-2.11110806  0.62583035  0.45005652  1.22712338  1.63690758]\n",
      " [ 0.57387668  0.59011334 -0.83701569 -1.69171    -2.46078253]\n",
      " [-0.03103738  2.646415   -0.02879368 -1.72299635 -1.8322705 ]\n",
      " [-0.6493063  -2.23745131  1.01971734  0.62207824 -1.47380924]\n",
      " [ 0.29385772  1.01321876  1.01853347 -1.94049799  2.31425905]]\n",
      "----------\n",
      "[ 0.25973171  1.79872894  0.31376514  0.14544843  0.24548735]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(W1))\n",
    "print('----------')\n",
    "print(sess.run(b1))\n",
    "print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.44189197  2.8260026   0.98790789 -0.26362282  0.19735223]\n",
      " [ 1.57507682  0.89698321 -2.23318172  0.94881558  0.03344214]\n",
      " [-1.8513763   2.42455935  0.76382166  1.37257183  1.88239491]\n",
      " [ 0.83360839  2.38884234 -0.52325058 -1.54626155 -2.21529508]\n",
      " [ 0.22869433  4.4451437   0.28497148 -1.57754791 -1.58678317]\n",
      " [-0.38957459 -0.43872237  1.3334825   0.76752669 -1.22832191]\n",
      " [ 0.55358946  2.81194782  1.33229864 -1.79504955  2.5597465 ]]\n"
     ]
    }
   ],
   "source": [
    "vectors=sess.run(W1+b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44189197  2.8260026   0.98790789 -0.26362282  0.19735223]\n"
     ]
    }
   ],
   "source": [
    "print(vectors[word2int['king']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_dist(vect1,vect2):\n",
    "    return np.sqrt(np.sum((vect1-vect2)**2))\n",
    "def find_closest(word_index,vectors):\n",
    "    min_dist=1000\n",
    "    min_index=-1\n",
    "    query_vector=vectors[word_index]\n",
    "    for index,vector in enumerate(vectors):\n",
    "        if euclid_dist(vector,query_vector)< min_dist and not np.array_equal(vector,query_vector):\n",
    "            min_dist=euclid_dist(vector,query_vector)\n",
    "            min_index=index\n",
    "    return min_index \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen\n"
     ]
    }
   ],
   "source": [
    "print(int2word[find_closest(word2int['king'], vectors)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.60416228  0.79686135]\n",
      " [ 0.94764328 -0.31933063]\n",
      " [-0.56901824 -0.82232487]\n",
      " [-0.50752604 -0.8616364 ]\n",
      " [ 0.25788736 -0.96617496]\n",
      " [-0.59571677  0.80319452]\n",
      " [-0.99601877 -0.08914335]]\n",
      "set(['king', 'is', 'queen', 'royal', 'she', 'the', 'he'])\n",
      "('king', 0.79686135)\n",
      "('is', -0.31933063)\n",
      "('queen', -0.82232487)\n",
      "('royal', -0.8616364)\n",
      "('she', -0.96617496)\n",
      "('the', 0.80319452)\n",
      "('he', -0.089143351)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f98e2305c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vectors) \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "normalizer = preprocessing.Normalizer()\n",
    "vectors =  normalizer.fit_transform(vectors, 'l2')\n",
    "\n",
    "print(vectors)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "print(words)\n",
    "for word in words:\n",
    "    print(word, vectors[word2int[word]][1])\n",
    "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
    "plt.axis([-1.5,2,-1.5,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
